{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFIA Importer\n",
    "[![Static Badge](https://img.shields.io/badge/Jupyter_Notebook-F37726?style=for-the-badge)](https://jupyter.org/)\n",
    "\n",
    "<br>\n",
    "\n",
    "## Requirements\n",
    "- Python (Version 3.6 or up)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Install Required Dependencies\n",
    "Run the code block below to install the required dependencies.\n",
    "\n",
    "<br>\n",
    "\n",
    "> ***üìù NOTE:*** <br>\n",
    ">\n",
    "> If you already have the required dependencies, you can *optionally* run the code block below.\n",
    "> \n",
    "> (For this case, running the code will only import the required libraries without sending any HTTP server requests to Pypi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Note: The code below is modified from AGRemap for dynamically installing\n",
    "#   packages at runtime. That way, we do not need to make extra HTTP requests\n",
    "#   to Pypi's server if the user's python environment already has the required libraries\n",
    "#\n",
    "# Reference:\n",
    "#    https://github.com/nhok0169/Anime-Game-Remap/blob/nhok0169/Anime%20Game%20Remap%20(for%20all%20users)/api/src/FixRaidenBoss2/tools/PackageManager.py\n",
    "#    https://github.com/nhok0169/Anime-Game-Remap/blob/nhok0169/Anime%20Game%20Remap%20(for%20all%20users)/api/src/FixRaidenBoss2/tools/PackageData.py\n",
    "\n",
    "\n",
    "import pip._internal as pip\n",
    "import importlib\n",
    "from types import ModuleType\n",
    "from typing import Optional, Dict\n",
    "\n",
    "\n",
    "# PackageData: Class to hold data for importing a package\n",
    "class PackageData():\n",
    "    def __init__(self, module: str, installName: Optional[str] = None):\n",
    "        self.module = module\n",
    "        self.installName = module if (installName is None) else installName\n",
    "\n",
    "\n",
    "# PackageManager: Class to manage the packages\n",
    "class PackageManager():\n",
    "    def __init__(self):\n",
    "        self._packages: Dict[str, ModuleType] = {}\n",
    "\n",
    "    # load(module, installName, save): Tries to import a package and install the package if the package\n",
    "    #   is not installed yet. Can optionally save to cache.\n",
    "    def load(self, module: str, installName: Optional[str] = None, save: bool = True) -> ModuleType:\n",
    "        if (installName is None):\n",
    "            installName = module\n",
    "\n",
    "        try:\n",
    "            return importlib.import_module(module)\n",
    "        except ModuleNotFoundError:\n",
    "            pip.main(['install', '-U', installName])\n",
    "\n",
    "        result = importlib.import_module(module)\n",
    "        if (save):\n",
    "            self._packages[module] = result\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # get(packageData, cache): Retrieves a package and installs the package if the package is not installed yet.\n",
    "    #   Has optional caching capability.\n",
    "    def get(self, packageData: PackageData, cache: bool = True) -> ModuleType:\n",
    "        if (not cache):\n",
    "            return self.load(packageData.module, installName = packageData.installName, save = cache)\n",
    "\n",
    "        result = None\n",
    "        try:\n",
    "            result = self._packages[packageData.module]\n",
    "        except KeyError:\n",
    "            result = self.load(packageData.module, installName = packageData.installName, save = cache)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "##############################\n",
    "# The required installations #\n",
    "# ############################\n",
    "Packages = [\n",
    "    PackageData(\"pandas\"),\n",
    "    PackageData(\"openpyxl\")\n",
    "]\n",
    "\n",
    "Packager = PackageManager()\n",
    "\n",
    "for package in Packages:\n",
    "    Packager.get(package, cache = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## User Settings\n",
    "\n",
    "Below shows some configurations that may be different depending on the user.\n",
    "\n",
    "<br>\n",
    "\n",
    "> ***‚ùáÔ∏è Important***\n",
    ">\n",
    "> Please ensure settings below are configured correctly.\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The folder where the raw data files are located\n",
    "DataFolder = \"data\"\n",
    "\n",
    "# The file location to the output files \n",
    "OutputFolder = os.path.join(\"..\", \"..\", \"data\")\n",
    "OutputFileName = \"CFIA Data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Running the Importer\n",
    "\n",
    "The code blocks below cleans up the raw CFIA data files to look similar to the Health Canada data\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing CSV output for language: en ...\n",
      "Writing CSV output for language: fr ...\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from threading import Lock, Thread\n",
    "from enum import Enum\n",
    "from typing import List, Dict, Callable\n",
    "\n",
    "\n",
    "# Languages: Different languages available\n",
    "class Languages(Enum):\n",
    "    English = \"en\"\n",
    "    French = \"fr\"\n",
    "\n",
    "\n",
    "# CFIADataCols: Different columns for the CFIA data\n",
    "class CFIADataCols(Enum):\n",
    "    FoodGroup = \"Food Group\"\n",
    "    FoodName = \"Food Name\"\n",
    "    Agent = \"Agent\"\n",
    "    Genus = \"Genus\"\n",
    "    Species = \"Species\"\n",
    "    SeroType = \"Serotype\"\n",
    "    EColiCategory = \"Ecoli CFIA Category\"\n",
    "    Result = \"Result\"\n",
    "    QualitativeResult = \"Qualitative Result\"\n",
    "    QuantitativeResult = \"Quantitative Result\"\n",
    "    QuantitativeResultOperator = \"Quantitative Result Operator\"\n",
    "    QuantitativeResultUnit = \"Quantitative Result Unit\"\n",
    "    ProductDescription = \"Product Description\"\n",
    "    CountryOfOrigin = \"Country of Origin\"\n",
    "    ResultComments = \"Result Comments\"\n",
    "    SamplingLocationCityName = \"Sampling Location City Name\"\n",
    "    ProjectCode = \"Project Code\"\n",
    "    MethodComments = \"Method Comments\"\n",
    "\n",
    "\n",
    "# CFIAStrConsts: Some string keywords used in the raw CFIA data\n",
    "class CFIAStrConsts(Enum):\n",
    "    LangSeperator = \"//\"\n",
    "\n",
    "\n",
    "# index position for each language part in to retrieve from the raw CFIA data\n",
    "CFIALangPos = {Languages.English: 0, Languages.French: 1}\n",
    "\n",
    "# Columns to have english and french seperated\n",
    "CFIALangSeperatedCols = [CFIADataCols.FoodName.value, CFIADataCols.QuantitativeResultUnit.value, \n",
    "                         CFIADataCols.ProductDescription.value, CFIADataCols.CountryOfOrigin.value, \n",
    "                         CFIADataCols.ResultComments.value, CFIADataCols.SamplingLocationCityName.value,\n",
    "                         CFIADataCols.ProjectCode.value, CFIADataCols.MethodComments.value]\n",
    "\n",
    "# Columns that need translations\n",
    "CFIANeedTranslationCols = [CFIADataCols.FoodGroup.value]\n",
    "\n",
    "# Translations for certain keywords\n",
    "Translations = {\n",
    "    Languages.English: {\n",
    "        CFIADataCols.FoodGroup.value: {\n",
    "            'Fish and fish products, including mollusks, crustaceans, and echinoderms': 'Fish and fish products, including mollusks, crustaceans, and echinoderms', \n",
    "            'Foodstuffs intended for particular nutritional uses': 'Foodstuffs intended for particular nutritional uses', \n",
    "            'Dairy products and analogues, excl butter ': 'Dairy products and analogues, excl butter ', \n",
    "            'Meat and meat products, including poultry and game': 'Meat and meat products, including poultry and game', \n",
    "            'Fruits and vegetables (incl fungi, legumes, aloe), seaweeds, nuts, seeds': 'Fruits and vegetables (incl fungi, legumes, aloe), seaweeds, nuts, seeds', \n",
    "            'Environmental Samples': 'Environmental Samples', \n",
    "            'Eggs and egg products': 'Eggs and egg products'\n",
    "        },\n",
    "\n",
    "        CFIADataCols.EColiCategory.value: {\n",
    "            \"O157\": \"O157\", \n",
    "            \"Verotoxigenic\": \"Verotoxigenic\"\n",
    "        },\n",
    "\n",
    "        CFIADataCols.QualitativeResult.value: {\n",
    "            \"Detected\": \"Detected\",\n",
    "            \"Not Detected\": \"Not Detected\",\n",
    "            \"Not Tested\": \"Not Tested\"\n",
    "        }\n",
    "    },\n",
    "    Languages.French: {\n",
    "        CFIADataCols.FoodGroup.value: {\n",
    "            'Fish and fish products, including mollusks, crustaceans, and echinoderms': 'Fish and fish products, including mollusks, crustaceans, and echinoderms', \n",
    "            'Foodstuffs intended for particular nutritional uses': 'Foodstuffs intended for particular nutritional uses', \n",
    "            'Dairy products and analogues, excl butter ': 'Dairy products and analogues, excl butter ', \n",
    "            'Meat and meat products, including poultry and game': 'Meat and meat products, including poultry and game', \n",
    "            'Fruits and vegetables (incl fungi, legumes, aloe), seaweeds, nuts, seeds': 'Fruits and vegetables (incl fungi, legumes, aloe), seaweeds, nuts, seeds', \n",
    "            'Environmental Samples': 'Environmental Samples', \n",
    "            'Eggs and egg products': 'Eggs and egg products'\n",
    "        },\n",
    "\n",
    "        CFIADataCols.EColiCategory.value: {\n",
    "            \"O157\": \"O157\", \n",
    "            \"Verotoxigenic\": \"Verotoxigenic\"\n",
    "        },\n",
    "\n",
    "        CFIADataCols.QualitativeResult.value: {\n",
    "            \"Detected\": \"Detected\",\n",
    "            \"Not Detected\": \"Not Detected\",\n",
    "            \"Not Tested\": \"Not Tested\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# ThreadManager: Class to manage running many threads\n",
    "class ThreadManager():\n",
    "    def __init__(self):\n",
    "        self.threads = []\n",
    "\n",
    "    # clear(): Clears all the threads\n",
    "    def clear(self):\n",
    "        self.threads.clear()\n",
    "\n",
    "    # add(*args, **kwargs): Adds a thread\n",
    "    def add(self, *args, **kwargs):\n",
    "        self.threads.append(Thread(*args, **kwargs))\n",
    "\n",
    "    # waitAll(): Runs all the threads at once and waits for all the threads to finish\n",
    "    def waitAll(self):\n",
    "        for thread in self.threads:\n",
    "            thread.start()\n",
    "\n",
    "        for thread in self.threads:\n",
    "            thread.join()\n",
    "\n",
    "\n",
    "# Importer: Class to cleanup the CFIA data\n",
    "class Importer():\n",
    "    def __init__(self, dataFolder: str = DataFolder, outputFolder: str = OutputFolder, outputFileName: str = OutputFileName):\n",
    "        self.dataFolder = dataFolder\n",
    "        self.outputFolder = outputFolder\n",
    "        self.outputFileName = outputFileName\n",
    "\n",
    "        self._outputDataLocks = {}\n",
    "        self._outputData = {}\n",
    "\n",
    "        for lang in Languages:\n",
    "            self._outputDataLocks[lang] = Lock()\n",
    "            self._outputData[lang] = None\n",
    "\n",
    "    # _translateCol(col, rawData, data, dataLocks): Translates all the values in a single column\n",
    "    def _translateCol(self, col: str, rawData: pd.DataFrame, data: Dict[Languages, pd.DataFrame], dataLocks: Dict[Languages, Lock]):\n",
    "        colVals = rawData[col]\n",
    "\n",
    "        for lang in Languages:\n",
    "            translations = Translations[lang].get(col)\n",
    "            if (translations is None):\n",
    "                continue\n",
    "\n",
    "            data[col] = colVals.apply(lambda colVal: translations.get(colVal, colVal))\n",
    "\n",
    "    # _translate(rawData, data, dataLocks): Translates certain columns from the raw data\n",
    "    def _translate(self, rawData: pd.DataFrame, data: Dict[Languages, pd.DataFrame], dataLocks: Dict[Languages, Lock]):\n",
    "        threads = ThreadManager()\n",
    "        for col in CFIANeedTranslationCols:\n",
    "            threads.add(target = self._translateCol, args = [col, rawData, data, dataLocks], daemon=True)\n",
    "\n",
    "        threads.waitAll()\n",
    "\n",
    "    # _seperateTranslationCol(colValue): Seperate out a value consisting of the combined\n",
    "    #   translations into individual translated parts\n",
    "    @classmethod\n",
    "    def _seperateTranslationVal(cls, colValue: str) -> List[str]:\n",
    "        result = colValue.split(CFIAStrConsts.LangSeperator.value)\n",
    "        result = list(map(lambda translatedPart: translatedPart.strip(), result))\n",
    "\n",
    "        langLen = len(Languages)\n",
    "        resultLen = len(result)\n",
    "\n",
    "        if (resultLen == langLen):\n",
    "            return result\n",
    "        elif (resultLen > langLen):\n",
    "            return result[:langLen]\n",
    "        \n",
    "        for i in range(resultLen, langLen):\n",
    "            result.append(result[0])\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # _seperateTranslationCol(col, rawData, data, dataLocks): Seperate out the combined translated values in a column\n",
    "    def _seperateTranslationCol(self, col: str, rawData: pd.DataFrame, data: Dict[Languages, pd.DataFrame], dataLocks: Dict[Languages, Lock]):\n",
    "        colVals = rawData.get(col)\n",
    "        if (colVals is None):\n",
    "            return\n",
    "\n",
    "        colVals = colVals.apply(self._seperateTranslationVal)\n",
    "\n",
    "        for lang in Languages:\n",
    "            currentData = data[lang]\n",
    "            langInd = CFIALangPos[lang]\n",
    "            lock = dataLocks[lang]\n",
    "\n",
    "            with lock:\n",
    "                currentData[col] = colVals.apply(lambda langFoodGroups: langFoodGroups[langInd])\n",
    "\n",
    "    # _seperateTranslations(rawData, data, rawDataLock, dataLocks): Seperate out the combined translated values from the raw data\n",
    "    #   for each seperate language result data\n",
    "    def _seperateTranslations(self, rawData: pd.DataFrame, data: Dict[Languages, pd.DataFrame], dataLocks: Dict[Languages, Lock]):\n",
    "        colThreads = ThreadManager()\n",
    "        for col in CFIALangSeperatedCols:\n",
    "            colThreads.add(target = self._seperateTranslationCol, args = [col, rawData, data, dataLocks], daemon=True)\n",
    "\n",
    "        colThreads.waitAll()\n",
    "\n",
    "    # _createLangEColiCategory(lang, eColiCategoryVals, eColiBitArr, data, dataLocks): Creates the E-Coli Category for the data of a particular language\n",
    "    def _createLangEColiCateogory(self, lang: Languages, eColiCategoryVals: np.array, eColiBitArr: List[pd.Series], data: Dict[Languages, pd.DataFrame], dataLocks: Dict[Languages, Lock]):\n",
    "        currentData = data[lang]\n",
    "        lock = dataLocks[lang]\n",
    "\n",
    "        translations = Translations[lang][CFIADataCols.EColiCategory.value]\n",
    "        eColiCategoryVals = np.select(eColiBitArr, [translations[\"O157\"], translations[\"Verotoxigenic\"]], default = \"\")\n",
    "\n",
    "        with lock:\n",
    "            currentData[CFIADataCols.EColiCategory.value] = eColiCategoryVals\n",
    "\n",
    "    # _createEColiCategory(rawData, data, dataLocks): Creates the E-Coli category for the microorganism breadcrumb\n",
    "    def _createEColiCategory(self, rawData: pd.DataFrame, data: Dict[Languages, pd.DataFrame], dataLocks: Dict[Languages, Lock]):\n",
    "        rowCount = len(rawData.index)\n",
    "        eColiCategoryVals = np.zeros(rowCount)\n",
    "\n",
    "        agentVals = rawData[CFIADataCols.Agent.value]\n",
    "        genusVals = rawData[CFIADataCols.Genus.value]\n",
    "        speciesVals = rawData[CFIADataCols.Species.value]\n",
    "        seroTypeVals = rawData[CFIADataCols.SeroType.value].fillna(\"\")\n",
    "\n",
    "        isEColi = ((agentVals == \"Bacteria\") & (genusVals == \"Escherichia\") & (speciesVals == \"coli\"))\n",
    "\n",
    "        seroTypeIsO157 = seroTypeVals.str.contains(pat = \"O157\", regex = False)\n",
    "        seroTypeNotO157 = ~seroTypeIsO157\n",
    "\n",
    "        eColiBitArr = [isEColi & seroTypeIsO157, isEColi & seroTypeNotO157]\n",
    "\n",
    "        threads = ThreadManager()\n",
    "        for lang in Languages:\n",
    "            threads.add(target = self._createLangEColiCateogory, args = [lang, eColiCategoryVals, eColiBitArr, data, dataLocks], daemon=True)\n",
    "\n",
    "        threads.waitAll()\n",
    "\n",
    "    def _readIndividual(self, key: str, combinedResult: Dict[str, pd.Series], combinedResultLock: Lock, readFunc: Callable[[], pd.Series], *args, **kwargs):\n",
    "        result = readFunc(*args, **kwargs)\n",
    "\n",
    "        with combinedResultLock:\n",
    "            combinedResult[key] = result\n",
    "\n",
    "    # _createLangQualitative(lang, qualitativeVals, bitArr, data, dataLocks): Creates the qualitative results column for the data of a certain language\n",
    "    def _createLangQualitative(self, lang: Languages, qualitativeVals: np.array, bitArr: List[pd.Series], data: Dict[Languages, pd.DataFrame], dataLocks: Dict[Languages, Lock]):\n",
    "        currentData = data[lang]\n",
    "        lock = dataLocks[lang]\n",
    "\n",
    "        translations = Translations[lang][CFIADataCols.QualitativeResult.value]\n",
    "        qualitativeVals = np.select(bitArr,[translations[\"Detected\"], translations[\"Not Detected\"], translations[\"Not Tested\"]], default = translations[\"Not Detected\"])\n",
    "\n",
    "        with lock:\n",
    "            currentData[CFIADataCols.QualitativeResult.value] = qualitativeVals\n",
    "\n",
    "    # _createLangQuantitativeResult(lang, data, dataLocks): Creates the quantitative results column for the data of a certain language\n",
    "    def _createLangQuantitativeResult(self, lang: Languages, bitArr: pd.Series, data: Dict[Languages, pd.DataFrame], dataLocks: Dict[Languages, Lock]):\n",
    "        currentData = data[lang]\n",
    "        lock = dataLocks[lang]\n",
    "\n",
    "        quantitativeNums = currentData[CFIADataCols.Result.value].str.replace(\">|>=|=|~|<|<=| |\\t\", \"\", case = False, regex = True)\n",
    "\n",
    "        with lock:\n",
    "            currentData[CFIADataCols.QuantitativeResult.value] = np.where(bitArr, quantitativeNums, \"\")\n",
    "\n",
    "    # _createLangQuantitativeOperator(lang, bitArr, data, dataLocks): Creates the quantitative operator column for the data of a certain language\n",
    "    def _createLangQuantitativeOperator(self, lang: Languages, bitArr: pd.Series, data: Dict[Languages, pd.DataFrame], dataLocks: Dict[Languages, Lock]):\n",
    "        currentData = data[lang]\n",
    "        lock = dataLocks[lang]\n",
    "\n",
    "        quantitativeOps = currentData[CFIADataCols.Result.value].str.replace(r\"[0-9]|-|\\.| |\\t\", \"\", case = False, regex = True)\n",
    "\n",
    "        with lock:\n",
    "            currentData[CFIADataCols.QuantitativeResultOperator.value] = np.where(bitArr, quantitativeOps, \"\")\n",
    "\n",
    "    # _createQualitativeAndQuantitative(rawData, data, dataLocks): Creates both the qualitative and quantitative results\n",
    "    def _createQualitativeAndQuantitative(self, rawData: pd.DataFrame, data: Dict[Languages, pd.DataFrame], dataLocks: Dict[Languages, Lock]):\n",
    "        rowCount = len(rawData.index)\n",
    "        resultVals = rawData[CFIADataCols.Result.value]\n",
    "        qualitative = np.zeros(rowCount)\n",
    "\n",
    "        bitArrDict = {}\n",
    "        bitArrsLock = Lock()\n",
    "\n",
    "        threads = ThreadManager()\n",
    "        threads.add(target = self._readIndividual, args = [\"isEmpty\", bitArrDict, bitArrsLock, lambda col: col.isna(), resultVals], daemon=True)\n",
    "        threads.add(target = self._readIndividual, args = [\"foundNotDetected\", bitArrDict, bitArrsLock, lambda col: col.str.contains(\"Not Detected\", case = False, na = False, regex = False), resultVals], daemon = True)\n",
    "        threads.add(target = self._readIndividual, args = [\"foundNotAnalyzed\", bitArrDict, bitArrsLock, lambda col: col.str.contains(\"Not Analyzed\", case = False, na = False, regex = False), resultVals], daemon = True)\n",
    "        threads.add(target = self._readIndividual, args = [\"foundDetected\", bitArrDict, bitArrsLock, lambda col: col.str.contains(\"^(?!.*Not).*Detected\", case = False, na = False, regex = True), resultVals], daemon = True)\n",
    "        threads.add(target = self._readIndividual, args = [\"foundPositive\", bitArrDict, bitArrsLock, lambda col: col.str.contains(r\"^( |\\t)*(((>|>=|=|~)( |\\t)*-?[0-9]*(\\.[0-9]+)?)|([1-9][0-9]*(\\.[0-9]+)?))( |\\t)*$\", case = False, na = False, regex = True), resultVals], daemon = True)\n",
    "        threads.add(target = self._readIndividual, args = [\"foundNonPositive\", bitArrDict, bitArrsLock, lambda col: col.str.contains(r\"^( |\\t)*(((<|<=)( |\\t)*-?[0-9]*(\\.[0-9]+)?)|0+(\\.[0-9]+)?|-[0-9]+(\\.[0-9]+)?)( |\\t)*$\", case = False, na = False, regex = True), resultVals], daemon = True)\n",
    "\n",
    "        threads.waitAll()\n",
    "\n",
    "        qualitativeBitArr = [bitArrDict[\"foundDetected\"] | bitArrDict[\"foundPositive\"], bitArrDict[\"foundNotDetected\"] | bitArrDict[\"foundNonPositive\"], bitArrDict[\"foundNotAnalyzed\"]]\n",
    "        quantitativeBitArr = bitArrDict[\"foundPositive\"] | bitArrDict[\"foundNonPositive\"]\n",
    "\n",
    "        threads.clear()\n",
    "        for lang in Languages:\n",
    "            threads.add(target = self._createLangQualitative, args = [lang, qualitative, qualitativeBitArr, data, dataLocks])\n",
    "            threads.add(target = self._createLangQuantitativeResult, args = [lang, quantitativeBitArr, data, dataLocks])\n",
    "            threads.add(target = self._createLangQuantitativeOperator, args = [lang, quantitativeBitArr, data, dataLocks])\n",
    "\n",
    "        threads.waitAll()\n",
    "\n",
    "    # _mergeLangProcessedData(lang, processedData): Writes back the processed data from a single excel file to the merged result\n",
    "    def _mergeLangProcessedData(self, lang: Languages, processedData: Dict[Languages, pd.DataFrame]):\n",
    "        lock = self._outputDataLocks[lang]\n",
    "\n",
    "        with lock:\n",
    "            outputData = self._outputData[lang]\n",
    "            self._outputData[lang] = processedData[lang].copy() if (outputData is None) else pd.concat([outputData, processedData[lang]])\n",
    "\n",
    "    # processFile(excelFile): Cleanups a single excel file and merges the\n",
    "    #   result into the output data\n",
    "    def processFile(self, excelFile: str):\n",
    "        rawData = pd.read_excel(excelFile)\n",
    "\n",
    "        resultData = {}\n",
    "        resultDataLocks = {}\n",
    "        for lang in Languages:\n",
    "            resultData[lang] = rawData.copy()\n",
    "            resultDataLocks[lang] = Lock()\n",
    "\n",
    "        # Since the procedure for cleaning/creating the columns do not have any data\n",
    "        #   that depend on each other, we can run all these procedures in parallel\n",
    "        threads = ThreadManager()\n",
    "        threads.add(target = self._translate, args = [rawData, resultData, resultDataLocks], daemon=True)\n",
    "        threads.add(target = self._seperateTranslations, args = [rawData, resultData, resultDataLocks], daemon=True)\n",
    "        threads.add(target = self._createEColiCategory, args = [rawData, resultData, resultDataLocks], daemon=True)\n",
    "        threads.add(target = self._createQualitativeAndQuantitative, args = [rawData, resultData, resultDataLocks], daemon = True)\n",
    "\n",
    "        threads.waitAll()\n",
    "\n",
    "        # write the processed data back to the combined output\n",
    "        threads.clear()\n",
    "        for lang in Languages:\n",
    "            threads.add(target = self._mergeLangProcessedData, args = [lang, resultData])\n",
    "\n",
    "        threads.waitAll()\n",
    "\n",
    "    # _writeResult(lang): Writes back the processed result into the CSV file\n",
    "    def _writeResult(self, lang: Languages):\n",
    "        outputData = self._outputData[lang]\n",
    "        if (outputData is None):\n",
    "            return\n",
    "\n",
    "        file = os.path.join(self.outputFolder, f\"{self.outputFileName}-{lang.value}.csv\")\n",
    "        print(f\"Writing CSV output for language: {lang.value} ...\\n\", end = \"\")\n",
    "        outputData.to_csv(file, index = False, encoding = \"utf-8\")\n",
    "\n",
    "    # run(): Runs the importer to create the cleaned-up data\n",
    "    def run(self):\n",
    "        excelFiles = glob.glob(os.path.join(f\"{self.dataFolder}\", \"*.xlsx\"))\n",
    "\n",
    "        # simultaneously process multiple excel files at the same time\n",
    "        threads = ThreadManager()\n",
    "        for excelFile in excelFiles:\n",
    "            threads.add(target = self.processFile, args=[excelFile], daemon=True)\n",
    "\n",
    "        threads.waitAll()\n",
    "\n",
    "        threads.clear()\n",
    "        for lang in Languages:\n",
    "            threads.add(target = self._writeResult, args = [lang])\n",
    "\n",
    "        threads.waitAll()\n",
    "\n",
    "########\n",
    "# MAIN #\n",
    "########\n",
    "importer = Importer()\n",
    "importer.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
