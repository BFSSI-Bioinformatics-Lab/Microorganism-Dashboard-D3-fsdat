{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFIA Importer\n",
    "[![Static Badge](https://img.shields.io/badge/Jupyter_Notebook-F37726?style=for-the-badge)](https://jupyter.org/)\n",
    "\n",
    "<br>\n",
    "\n",
    "## Requirements\n",
    "- Python (Version 3.6 or up)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Install Required Dependencies\n",
    "Run the code block below to install the required dependencies.\n",
    "\n",
    "<br>\n",
    "\n",
    "> ***üìù NOTE:*** <br>\n",
    ">\n",
    "> If you already have the required dependencies, you can *optionally* run the code block below.\n",
    "> \n",
    "> (For this case, running the code will only import the required libraries without sending any HTTP server requests to Pypi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Note: The code below is modified from AGRemap for dynamically installing\n",
    "#   packages at runtime. That way, we do not need to make extra HTTP requests\n",
    "#   to Pypi's server if the user's python environment already has the required libraries\n",
    "#\n",
    "# Reference:\n",
    "#    https://github.com/nhok0169/Anime-Game-Remap/blob/nhok0169/Anime%20Game%20Remap%20(for%20all%20users)/api/src/FixRaidenBoss2/tools/PackageManager.py\n",
    "#    https://github.com/nhok0169/Anime-Game-Remap/blob/nhok0169/Anime%20Game%20Remap%20(for%20all%20users)/api/src/FixRaidenBoss2/tools/PackageData.py\n",
    "\n",
    "\n",
    "import pip._internal as pip\n",
    "import importlib\n",
    "from types import ModuleType\n",
    "from typing import Optional, Dict\n",
    "\n",
    "\n",
    "# PackageData: Class to hold data for importing a package\n",
    "class PackageData():\n",
    "    def __init__(self, module: str, installName: Optional[str] = None):\n",
    "        self.module = module\n",
    "        self.installName = module if (installName is None) else installName\n",
    "\n",
    "\n",
    "# PackageManager: Class to manage the packages\n",
    "class PackageManager():\n",
    "    def __init__(self):\n",
    "        self._packages: Dict[str, ModuleType] = {}\n",
    "\n",
    "    # load(module, installName, save): Tries to import a package and install the package if the package\n",
    "    #   is not installed yet. Can optionally save to cache.\n",
    "    def load(self, module: str, installName: Optional[str] = None, save: bool = True) -> ModuleType:\n",
    "        if (installName is None):\n",
    "            installName = module\n",
    "\n",
    "        try:\n",
    "            return importlib.import_module(module)\n",
    "        except ModuleNotFoundError:\n",
    "            pip.main(['install', '-U', installName])\n",
    "\n",
    "        result = importlib.import_module(module)\n",
    "        if (save):\n",
    "            self._packages[module] = result\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # get(packageData, cache): Retrieves a package and installs the package if the package is not installed yet.\n",
    "    #   Has optional caching capability.\n",
    "    def get(self, packageData: PackageData, cache: bool = True) -> ModuleType:\n",
    "        if (not cache):\n",
    "            return self.load(packageData.module, installName = packageData.installName, save = cache)\n",
    "\n",
    "        result = None\n",
    "        try:\n",
    "            result = self._packages[packageData.module]\n",
    "        except KeyError:\n",
    "            result = self.load(packageData.module, installName = packageData.installName, save = cache)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "##############################\n",
    "# The required installations #\n",
    "# ############################\n",
    "Packages = [\n",
    "    PackageData(\"pandas\"),\n",
    "    PackageData(\"openpyxl\")\n",
    "]\n",
    "\n",
    "Packager = PackageManager()\n",
    "\n",
    "for package in Packages:\n",
    "    Packager.get(package, cache = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## User Settings\n",
    "\n",
    "Below shows some configurations that may be different depending on the user.\n",
    "\n",
    "<br>\n",
    "\n",
    "> ***‚ùáÔ∏è Important***\n",
    ">\n",
    "> Please ensure settings below are configured correctly.\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The folder where the raw data files are located\n",
    "DataFolder = \"data\"\n",
    "CFIADataFolder = os.path.join(DataFolder, \"CFIA\")\n",
    "HCDataFolder = os.path.join(DataFolder, \"Health Canada\")\n",
    "\n",
    "# The file location to the output files \n",
    "OutputFolder = os.path.join(\"..\", \"..\", \"data\")\n",
    "CFIAOutputFileName = \"CFIA Data\"\n",
    "HCOutputFileName = \"Health Canada Data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Running the Importer\n",
    "\n",
    "The code blocks below cleans up the raw CFIA data files to look similar to the Health Canada data\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HC CSV output for language: fr ...\n",
      "Writing HC CSV output for language: en ...\n",
      "Writing CFIA CSV output for language: fr ...\n",
      "Writing CFIA CSV output for language: en ...\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from threading import Lock, Thread\n",
    "from enum import Enum\n",
    "from typing import List, Dict, Callable\n",
    "\n",
    "\n",
    "# Languages: Different languages available\n",
    "class Languages(Enum):\n",
    "    English = \"en\"\n",
    "    French = \"fr\"\n",
    "\n",
    "\n",
    "# CFIADataCols: Different columns for the CFIA data\n",
    "class CFIADataCols(Enum):\n",
    "    FoodGroup = \"Food Group\"\n",
    "    FoodName = \"Food Name\"\n",
    "    Agent = \"Agent\"\n",
    "    Genus = \"Genus\"\n",
    "    Species = \"Species\"\n",
    "    SubSpecies = \"Subspecies/ Genogroup\"\n",
    "    GenoType = \"Genotype\"\n",
    "    SubGenoType = \"Subgenotype\"\n",
    "    SeroType = \"Serotype\"\n",
    "    OldOtherTyping = \"Other typing\"\n",
    "    NewOtherTyping = \"Other Typing\"\n",
    "    EColiCategory = \"Ecoli CFIA Category\"\n",
    "    EColiTyped = \"Ecoli Typed\"\n",
    "    IsVirulent = \"EColi Virulent\"\n",
    "    Result = \"Result\"\n",
    "    QualitativeResult = \"Qualitative Result\"\n",
    "    QuantitativeResult = \"Quantitative Result\"\n",
    "    QuantitativeResultOperator = \"Quantitative Result Operator\"\n",
    "    QuantitativeResultUnit = \"Quantitative Result Unit\"\n",
    "    ProductDescription = \"Product Description\"\n",
    "    CountryOfOrigin = \"Country of Origin\"\n",
    "    ResultComments = \"Result Comments\"\n",
    "    SamplingLocationCityName = \"Sampling Location City Name\"\n",
    "    ProjectCode = \"Project Code\"\n",
    "    ProjectName = \"Project Name\"\n",
    "    ProjectDescription = \"Project Description\"\n",
    "    MethodComments = \"Method Comments\"\n",
    "    MoreSampleInfo2 = \"More Sample Info 2\"\n",
    "    SampleCode = \"Sample Code\"\n",
    "    SampleCollectionDate = \"Sample Collection Date\"\n",
    "    TestMethodCode = \"Test Method Code\"\n",
    "\n",
    "\n",
    "# CFIAStrConsts: Some string keywords used in the raw CFIA data\n",
    "class CFIAStrConsts(Enum):\n",
    "    LangSeperator = \"//\"\n",
    "    Virulent = \"Virulent\"\n",
    "    NotVirulent = \"Not Virulent\"\n",
    "\n",
    "\n",
    "# index position for each language part in to retrieve from the raw CFIA data\n",
    "CFIALangPos = {Languages.English: 0, Languages.French: 1}\n",
    "\n",
    "# Columns to have english and french seperated\n",
    "CFIALangSeperatedCols = [CFIADataCols.FoodName.value, CFIADataCols.QuantitativeResultUnit.value, \n",
    "                         CFIADataCols.ProductDescription.value, CFIADataCols.CountryOfOrigin.value, \n",
    "                         CFIADataCols.ResultComments.value, CFIADataCols.SamplingLocationCityName.value,\n",
    "                         CFIADataCols.ProjectCode.value, CFIADataCols.MethodComments.value,\n",
    "                         CFIADataCols.SeroType.value]\n",
    "\n",
    "# Columns that need translations\n",
    "CFIANeedTranslationCols = [CFIADataCols.FoodGroup.value]\n",
    "\n",
    "# Order for the columns in the output file\n",
    "CFIAColOrder = [\n",
    "    CFIADataCols.MoreSampleInfo2.value,\n",
    "    CFIADataCols.FoodGroup.value,\n",
    "    CFIADataCols.FoodName.value,\n",
    "    CFIADataCols.SampleCollectionDate.value,\n",
    "    CFIADataCols.SampleCode.value,\n",
    "    CFIADataCols.SamplingLocationCityName.value,\n",
    "    CFIADataCols.CountryOfOrigin.value,\n",
    "    CFIADataCols.Agent.value,\n",
    "    CFIADataCols.Genus.value,\n",
    "    CFIADataCols.Species.value,\n",
    "    CFIADataCols.SubSpecies.value,\n",
    "    CFIADataCols.GenoType.value,\n",
    "    CFIADataCols.SubGenoType.value,\n",
    "    CFIADataCols.SeroType.value,\n",
    "    CFIADataCols.EColiCategory.value,\n",
    "    CFIADataCols.EColiTyped.value,\n",
    "    CFIADataCols.IsVirulent.value,\n",
    "    CFIADataCols.NewOtherTyping.value,\n",
    "    CFIADataCols.TestMethodCode.value,\n",
    "    CFIADataCols.MethodComments.value,\n",
    "    CFIADataCols.Result.value,\n",
    "    CFIADataCols.QualitativeResult.value,\n",
    "    CFIADataCols.QuantitativeResultOperator.value,\n",
    "    CFIADataCols.QuantitativeResult.value,\n",
    "    CFIADataCols.QuantitativeResultUnit.value,\n",
    "    CFIADataCols.ResultComments.value,\n",
    "    CFIADataCols.ProjectCode.value,\n",
    "    CFIADataCols.ProjectName.value,\n",
    "    CFIADataCols.ProjectDescription.value,\n",
    "    CFIADataCols.ProductDescription.value\n",
    "]\n",
    "\n",
    "CFIAStrCols = [\n",
    "    CFIADataCols.Agent.value,\n",
    "    CFIADataCols.Genus.value,\n",
    "    CFIADataCols.Species.value,\n",
    "    CFIADataCols.SubSpecies.value,\n",
    "    CFIADataCols.GenoType.value,\n",
    "    CFIADataCols.SubGenoType.value,\n",
    "    CFIADataCols.SeroType.value,\n",
    "    CFIADataCols.EColiCategory.value,\n",
    "    CFIADataCols.EColiTyped.value,\n",
    "    CFIADataCols.IsVirulent.value\n",
    "]\n",
    "\n",
    "\n",
    "# Translations for certain keywords\n",
    "Translations = {\n",
    "    Languages.English: {\n",
    "        CFIADataCols.FoodGroup.value: {\n",
    "            'Fish and fish products, including mollusks, crustaceans, and echinoderms': 'Fish and fish products, including mollusks, crustaceans, and echinoderms', \n",
    "            'Foodstuffs intended for particular nutritional uses': 'Foodstuffs intended for particular nutritional uses', \n",
    "            'Dairy products and analogues, excl butter ': 'Dairy products and analogues, excl butter ', \n",
    "            'Meat and meat products, including poultry and game': 'Meat and meat products, including poultry and game', \n",
    "            'Fruits and vegetables (incl fungi, legumes, aloe), seaweeds, nuts, seeds': 'Fruits and vegetables (incl fungi, legumes, aloe), seaweeds, nuts, seeds', \n",
    "            'Environmental Samples': 'Environmental Samples', \n",
    "            'Eggs and egg products': 'Eggs and egg products'\n",
    "        },\n",
    "\n",
    "        \"yes\": \"yes\",\n",
    "        \"no\": \"no\",\n",
    "\n",
    "        CFIADataCols.EColiCategory.value: {\n",
    "            \"O157\": \"O157\", \n",
    "            \"Verotoxigenic\": \"Verotoxigenic\"\n",
    "        },\n",
    "\n",
    "        CFIADataCols.EColiTyped.value: {\n",
    "            \"Typed\": \"Typed\",\n",
    "            \"Not Typed\": \"Not Typed\"\n",
    "        },\n",
    "\n",
    "        CFIADataCols.QualitativeResult.value: {\n",
    "            \"Detected\": \"Detected\",\n",
    "            \"Not Detected\": \"Not Detected\",\n",
    "            \"Not Tested\": \"Not Tested\"\n",
    "        }\n",
    "    },\n",
    "    Languages.French: {\n",
    "        CFIADataCols.FoodGroup.value: {\n",
    "            'Fish and fish products, including mollusks, crustaceans, and echinoderms': 'Fish and fish products, including mollusks, crustaceans, and echinoderms', \n",
    "            'Foodstuffs intended for particular nutritional uses': 'Foodstuffs intended for particular nutritional uses', \n",
    "            'Dairy products and analogues, excl butter ': 'Dairy products and analogues, excl butter ', \n",
    "            'Meat and meat products, including poultry and game': 'Meat and meat products, including poultry and game', \n",
    "            'Fruits and vegetables (incl fungi, legumes, aloe), seaweeds, nuts, seeds': 'Fruits and vegetables (incl fungi, legumes, aloe), seaweeds, nuts, seeds', \n",
    "            'Environmental Samples': 'Environmental Samples', \n",
    "            'Eggs and egg products': 'Eggs and egg products'\n",
    "        },\n",
    "\n",
    "        \"yes\": \"oui\",\n",
    "        \"no\": \"non\",\n",
    "\n",
    "        CFIADataCols.EColiCategory.value: {\n",
    "            \"O157\": \"O157\", \n",
    "            \"Verotoxigenic\": \"Verotoxigenic\"\n",
    "        },\n",
    "\n",
    "        CFIADataCols.EColiTyped.value: {\n",
    "            \"Typed\": \"Typed\",\n",
    "            \"Not Typed\": \"Not Typed\"\n",
    "        },\n",
    "\n",
    "        CFIADataCols.QualitativeResult.value: {\n",
    "            \"Detected\": \"Detected\",\n",
    "            \"Not Detected\": \"Not Detected\",\n",
    "            \"Not Tested\": \"Not Tested\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# ThreadManager: Class to manage running many threads\n",
    "class ThreadManager():\n",
    "    def __init__(self):\n",
    "        self.threads = []\n",
    "\n",
    "    # clear(): Clears all the threads\n",
    "    def clear(self):\n",
    "        self.threads.clear()\n",
    "\n",
    "    # add(*args, **kwargs): Adds a thread\n",
    "    def add(self, *args, **kwargs):\n",
    "        self.threads.append(Thread(*args, **kwargs))\n",
    "\n",
    "    # waitAll(): Runs all the threads at once and waits for all the threads to finish\n",
    "    def waitAll(self):\n",
    "        for thread in self.threads:\n",
    "            thread.start()\n",
    "\n",
    "        for thread in self.threads:\n",
    "            thread.join()\n",
    "\n",
    "\n",
    "# Importer: Base class for some data cleanup\n",
    "class Importer():\n",
    "    def __init__(self, dataFolder: str, outputFolder: str, outputFileName: str):\n",
    "        self.dataFolder = dataFolder\n",
    "        self.outputFolder = outputFolder\n",
    "        self.outputFileName = outputFileName\n",
    "\n",
    "        self._outputData = {}\n",
    "        for lang in Languages:\n",
    "            self._outputData[lang] = None\n",
    "\n",
    "    # isEColi(rawData): Retrieves whether a certain row contains Bacteria EColi microorganism\n",
    "    def isEColi(self, rawData: pd.DataFrame) -> pd.Series:\n",
    "        agentVals = rawData[CFIADataCols.Agent.value]\n",
    "        genusVals = rawData[CFIADataCols.Genus.value].fillna(\"\")\n",
    "        speciesVals = rawData[CFIADataCols.Species.value].fillna(\"\")\n",
    "\n",
    "        return ((agentVals == \"Bacteria\") & (genusVals == \"Escherichia\") & (speciesVals == \"coli\"))\n",
    "\n",
    "    # run(): Runs the importer\n",
    "    def run(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "# Importer: Class to cleanup the CFIA data\n",
    "class CFIAImporter(Importer):\n",
    "    def __init__(self, dataFolder: str = CFIADataFolder, outputFolder: str = OutputFolder, outputFileName: str = CFIAOutputFileName):\n",
    "        super().__init__(dataFolder, outputFolder, outputFileName)\n",
    "\n",
    "        self._outputDataLocks = {}\n",
    "        for lang in Languages:\n",
    "            self._outputDataLocks[lang] = Lock()\n",
    "\n",
    "    # _translateCol(col, rawData, data): Translates all the values in a single column\n",
    "    def _translateCol(self, col: str, rawData: pd.DataFrame, data: Dict[Languages, pd.DataFrame]):\n",
    "        colVals = rawData[col]\n",
    "\n",
    "        for lang in Languages:\n",
    "            translations = Translations[lang].get(col)\n",
    "            if (translations is None):\n",
    "                continue\n",
    "\n",
    "            data[col] = colVals.apply(lambda colVal: translations.get(colVal, colVal))\n",
    "\n",
    "    # _translate(rawData, data): Translates certain columns from the raw data\n",
    "    def _translate(self, rawData: pd.DataFrame, data: Dict[Languages, pd.DataFrame]):\n",
    "        for col in CFIANeedTranslationCols:\n",
    "            self._translateCol(col, rawData, data)\n",
    "\n",
    "    # _seperateTranslationCol(colValue): Seperate out a value consisting of the combined\n",
    "    #   translations into individual translated parts\n",
    "    @classmethod\n",
    "    def _seperateTranslationVal(cls, colValue: str) -> List[str]:\n",
    "        result = colValue.split(CFIAStrConsts.LangSeperator.value)\n",
    "        result = list(map(lambda translatedPart: translatedPart.strip(), result))\n",
    "\n",
    "        langLen = len(Languages)\n",
    "        resultLen = len(result)\n",
    "\n",
    "        if (resultLen == langLen):\n",
    "            return result\n",
    "        elif (resultLen > langLen):\n",
    "            return result[:langLen]\n",
    "        \n",
    "        for i in range(resultLen, langLen):\n",
    "            result.append(result[0])\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # _seperateTranslationCol(col, rawData, data): Seperate out the combined translated values in a column\n",
    "    def _seperateTranslationCol(self, col: str, rawData: pd.DataFrame, data: Dict[Languages, pd.DataFrame]):\n",
    "        colVals = rawData.get(col)\n",
    "        if (colVals is None):\n",
    "            return\n",
    "\n",
    "        colVals = colVals.astype(str)[colVals.notnull()]\n",
    "        colVals = colVals.apply(self._seperateTranslationVal)\n",
    "\n",
    "        for lang in Languages:\n",
    "            currentData = data[lang]\n",
    "            langInd = CFIALangPos[lang]\n",
    "            currentData[col] = colVals.apply(lambda langFoodGroups: langFoodGroups[langInd])\n",
    "\n",
    "    # _seperateTranslations(rawData, data, rawDataLock): Seperate out the combined translated values from the raw data\n",
    "    #   for each seperate language result data\n",
    "    def _seperateTranslations(self, rawData: pd.DataFrame, data: Dict[Languages, pd.DataFrame]):\n",
    "        for col in CFIALangSeperatedCols:\n",
    "            self._seperateTranslationCol(col, rawData, data)\n",
    "\n",
    "    # _createLangEColiCategory(lang, eColiBitArr, data): Creates the E-Coli Category for the data of a particular language\n",
    "    def _createLangEColiCateogory(self, lang: Languages, eColiBitArr: List[pd.Series], data: Dict[Languages, pd.DataFrame]):\n",
    "        currentData = data[lang]\n",
    "\n",
    "        translations = Translations[lang][CFIADataCols.EColiCategory.value]\n",
    "        eColiCategoryVals = np.select(eColiBitArr, [translations[\"O157\"], translations[\"Verotoxigenic\"]], default = \"\")\n",
    "\n",
    "        currentData[CFIADataCols.EColiCategory.value] = eColiCategoryVals\n",
    "\n",
    "    # _createLangEColiTyped(lang, eColiBitArr, data): Creates the E-Coli Typed column for the data of a particular language\n",
    "    def _createLangEColiTyped(self, lang: Languages, eColiBitArr: List[pd.Series], data: Dict[Languages, pd.DataFrame]):\n",
    "        currentData = data[lang]\n",
    "\n",
    "        translations = Translations[lang][CFIADataCols.EColiTyped.value]\n",
    "        eColiTypedVals = np.select(eColiBitArr, [translations[\"Typed\"], translations[\"Not Typed\"]], default = \"\")\n",
    "\n",
    "        currentData[CFIADataCols.EColiTyped.value] = eColiTypedVals\n",
    "\n",
    "    # _createEColiCategory(rawData, data, dataLocks): Creates the E-Coli category for the microorganism breadcrumb\n",
    "    def _createEColiCategory(self, rawData: pd.DataFrame, data: Dict[Languages, pd.DataFrame]) -> np.array:\n",
    "        seroTypeVals = rawData[CFIADataCols.SeroType.value].fillna(\"\")\n",
    "        otherTypingVals = rawData[CFIADataCols.NewOtherTyping.value].fillna(\"\")\n",
    "\n",
    "        isEColi = self.isEColi(rawData)\n",
    "\n",
    "        seroTypeIsO157 = seroTypeVals.str.contains(pat = \"O157\", regex = False)\n",
    "        seroTypeNotO157 = ~seroTypeIsO157\n",
    "        eColiCateogryBitArr = [isEColi & seroTypeIsO157, isEColi & seroTypeNotO157]\n",
    "\n",
    "        isNotTyped = (seroTypeVals == \"\") & (otherTypingVals == \"\")\n",
    "        isTyped = ~isNotTyped\n",
    "        eColiTypedBitArr = [isEColi & isTyped, isEColi & isNotTyped]\n",
    "\n",
    "        for lang in Languages:\n",
    "            self._createLangEColiCateogory(lang, eColiCateogryBitArr, data)\n",
    "            self._createLangEColiTyped(lang, eColiTypedBitArr, data)\n",
    "\n",
    "        return isTyped\n",
    "\n",
    "    # _createLangIsVirulent(lang, virulentBitArr, data): \n",
    "    def _createLangIsVirulent(self, lang: Languages, virulentBitArr: List[pd.Series], data: Dict[Languages, pd.DataFrame]):\n",
    "        currentData = data[lang]\n",
    "\n",
    "        eColiTypedVals = np.select(virulentBitArr, [CFIAStrConsts.Virulent.value, CFIAStrConsts.NotVirulent.value], default = \"\")\n",
    "\n",
    "        currentData[CFIADataCols.IsVirulent.value] = eColiTypedVals\n",
    "\n",
    "    # _createEColiCategory(rawData, data, eColiTyped): Creates the isVirulent flag column for Bacteria EColi\n",
    "    def _createIsVirulent(self, rawData: pd.DataFrame, data: Dict[Languages, pd.DataFrame], eColiTyped: np.array):\n",
    "        seroTypeVals = rawData[CFIADataCols.SeroType.value].fillna(\"\")\n",
    "        seroTypeVals = seroTypeVals.str.replace(f\"{CFIAStrConsts.LangSeperator.value}.*\", \"\")\n",
    "\n",
    "        commaPrefixedPatternStr = \".*,\"\n",
    "        isCommaPrefixed = seroTypeVals.str.match(commaPrefixedPatternStr)\n",
    "\n",
    "        seroTypeVals = seroTypeVals.str.replace(commaPrefixedPatternStr, \"\", regex = True, n = 1)\n",
    "        hasDetectedAfterComma = seroTypeVals.str.contains(pat = f\"detected\", case = False)\n",
    "\n",
    "        isEColi = self.isEColi(rawData)\n",
    "\n",
    "        isVirulent = isCommaPrefixed & ~hasDetectedAfterComma\n",
    "        isNotVirulent = ~isVirulent\n",
    "\n",
    "        virulentBitArr = [isEColi & eColiTyped & isVirulent, isEColi & eColiTyped & isNotVirulent]\n",
    "\n",
    "        for lang in Languages:\n",
    "            self._createLangIsVirulent(lang, virulentBitArr, data)\n",
    "\n",
    "    def _readIndividual(self, key: str, combinedResult: Dict[str, pd.Series], readFunc: Callable[[], pd.Series], *args, **kwargs):\n",
    "        result = readFunc(*args, **kwargs)\n",
    "        combinedResult[key] = result\n",
    "\n",
    "    # _createLangQualitative(lang, qualitativeVals, bitArr, data): Creates the qualitative results column for the data of a certain language\n",
    "    def _createLangQualitative(self, lang: Languages, qualitativeVals: np.array, bitArr: List[pd.Series], data: Dict[Languages, pd.DataFrame]):\n",
    "        currentData = data[lang]\n",
    "\n",
    "        translations = Translations[lang][CFIADataCols.QualitativeResult.value]\n",
    "        qualitativeVals = np.select(bitArr,[translations[\"Detected\"], translations[\"Not Detected\"], translations[\"Not Tested\"]], default = translations[\"Not Detected\"])\n",
    "\n",
    "        currentData[CFIADataCols.QualitativeResult.value] = qualitativeVals\n",
    "\n",
    "    # _createLangQuantitativeResult(lang, data): Creates the quantitative results column for the data of a certain language\n",
    "    def _createLangQuantitativeResult(self, lang: Languages, bitArr: pd.Series, data: Dict[Languages, pd.DataFrame]):\n",
    "        currentData = data[lang]\n",
    "        resultVals = currentData[CFIADataCols.Result.value].astype(str)[currentData[CFIADataCols.Result.value].notnull()]\n",
    "\n",
    "        quantitativeNums = resultVals.str.replace(\">|>=|=|~|<|<=| |\\t\", \"\", case = False, regex = True)\n",
    "\n",
    "        currentData[CFIADataCols.QuantitativeResult.value] = np.where(bitArr, quantitativeNums, \"\")\n",
    "\n",
    "    # _createLangQuantitativeOperator(lang, bitArr, data): Creates the quantitative operator column for the data of a certain language\n",
    "    def _createLangQuantitativeOperator(self, lang: Languages, bitArr: pd.Series, data: Dict[Languages, pd.DataFrame]):\n",
    "        currentData = data[lang]\n",
    "        resultVals = currentData[CFIADataCols.Result.value].astype(str)[currentData[CFIADataCols.Result.value].notnull()]\n",
    "\n",
    "        quantitativeOps = resultVals.str.replace(r\"[0-9]|-|\\.| |\\t\", \"\", case = False, regex = True)\n",
    "        isBlank = quantitativeOps == \"\"\n",
    "\n",
    "        currentData[CFIADataCols.QuantitativeResultOperator.value] = np.select([bitArr & isBlank, bitArr & ~isBlank], [\"=\", quantitativeOps], default = \"\")\n",
    "\n",
    "    # _createQualitativeAndQuantitative(rawData, data): Creates both the qualitative and quantitative results\n",
    "    def _createQualitativeAndQuantitative(self, rawData: pd.DataFrame, data: Dict[Languages, pd.DataFrame]):\n",
    "        rowCount = len(rawData.index)\n",
    "        resultVals = rawData[CFIADataCols.Result.value].astype(str)[rawData[CFIADataCols.Result.value].notnull()]\n",
    "        qualitative = np.zeros(rowCount)\n",
    "\n",
    "        bitArrDict = {}\n",
    "\n",
    "        self._readIndividual(\"isEmpty\", bitArrDict, lambda col: col.isna(), resultVals)\n",
    "        self._readIndividual(\"foundNotDetected\", bitArrDict, lambda col: col.str.contains(\"Not Detected\", case = False, na = False, regex = False), resultVals)\n",
    "        self._readIndividual(\"foundNotAnalyzed\", bitArrDict, lambda col: col.str.contains(\"Not Analyzed\", case = False, na = False, regex = False), resultVals)\n",
    "        self._readIndividual(\"foundDetected\", bitArrDict, lambda col: col.str.match(\"^((?!Not).)*Detected\", case = False, na = False), resultVals)\n",
    "        self._readIndividual(\"foundPositive\", bitArrDict, lambda col: col.str.match(\"^( |\\t)*(((>|>=|=|~)( |\\t)*-?[0-9]*(\\.[0-9]+)?)|([1-9][0-9]*(\\.[0-9]+)?))( |\\t)*$\", na = False), resultVals)\n",
    "        self._readIndividual(\"foundNonPositive\", bitArrDict, lambda col: col.str.match(\"^( |\\t)*(((<|<=)( |\\t)*-?[0-9]*(\\.[0-9]+)?)|0+(\\.[0-9]+)?|-[0-9]+(\\.[0-9]+)?)( |\\t)*$\", na = False), resultVals)\n",
    "\n",
    "        qualitativeBitArr = [bitArrDict[\"foundDetected\"] | bitArrDict[\"foundPositive\"], bitArrDict[\"foundNotDetected\"] | bitArrDict[\"foundNonPositive\"], bitArrDict[\"foundNotAnalyzed\"]]\n",
    "        quantitativeBitArr = bitArrDict[\"foundPositive\"] | bitArrDict[\"foundNonPositive\"]\n",
    "\n",
    "        for lang in Languages:\n",
    "            self._createLangQualitative(lang, qualitative, qualitativeBitArr, data)\n",
    "            self._createLangQuantitativeResult(lang, quantitativeBitArr, data)\n",
    "            self._createLangQuantitativeOperator(lang, quantitativeBitArr, data)\n",
    "\n",
    "    # _mergeLangProcessedData(lang, processedData): Writes back the processed data from a single excel file to the merged result\n",
    "    def _mergeLangProcessedData(self, lang: Languages, processedData: Dict[Languages, pd.DataFrame]):\n",
    "        lock = self._outputDataLocks[lang]\n",
    "\n",
    "        with lock:\n",
    "            outputData = self._outputData[lang]\n",
    "            self._outputData[lang] = processedData[lang].copy() if (outputData is None) else pd.concat([outputData, processedData[lang]])\n",
    "\n",
    "    # processFile(excelFile): Cleanups a single excel file and merges the\n",
    "    #   result into the output data\n",
    "    def processFile(self, excelFile: str):\n",
    "        rawData = pd.read_excel(excelFile)\n",
    "\n",
    "        resultData = {}\n",
    "        for lang in Languages:\n",
    "            resultData[lang] = rawData.copy()\n",
    "\n",
    "        rawData.rename(columns = {CFIADataCols.OldOtherTyping.value: CFIADataCols.NewOtherTyping.value}, inplace = True)\n",
    "\n",
    "        self._translate(rawData, resultData)\n",
    "        self._seperateTranslations(rawData, resultData)\n",
    "        isEColiTyped = self._createEColiCategory(rawData, resultData)\n",
    "        self._createQualitativeAndQuantitative(rawData, resultData)\n",
    "        self._createIsVirulent(rawData, resultData, isEColiTyped)\n",
    "\n",
    "        # write the processed data back to the combined output\n",
    "        for lang in Languages:\n",
    "            self._mergeLangProcessedData(lang, resultData)\n",
    "\n",
    "    # _writeResult(lang): Writes back the processed result into the CSV file\n",
    "    def _writeResult(self, lang: Languages):\n",
    "        outputData = self._outputData[lang]\n",
    "        if (outputData is None):\n",
    "            return\n",
    "        \n",
    "        # reorder the columns\n",
    "        outputData = outputData[CFIAColOrder]\n",
    "\n",
    "        # convert the columns to string\n",
    "        outputData = outputData.fillna('')\n",
    "        outputData[CFIAStrCols] = outputData[CFIAStrCols].astype(str)[outputData.notnull()]\n",
    "\n",
    "        file = os.path.join(self.outputFolder, f\"{self.outputFileName}-{lang.value}.csv\")\n",
    "        print(f\"Writing CFIA CSV output for language: {lang.value} ...\\n\", end = \"\")\n",
    "        outputData.to_csv(file, index = False, encoding = \"utf-8\")\n",
    "\n",
    "    def run(self):\n",
    "        excelFiles = glob.glob(os.path.join(f\"{self.dataFolder}\", \"*.xlsx\"))\n",
    "\n",
    "        threads = ThreadManager()\n",
    "        for excelFile in excelFiles:\n",
    "            threads.add(target = self.processFile, args=[excelFile], daemon=True)\n",
    "\n",
    "        threads.waitAll()\n",
    "\n",
    "        threads.clear()\n",
    "        for lang in Languages:\n",
    "            threads.add(target = self._writeResult, args = [lang])\n",
    "\n",
    "        threads.waitAll()\n",
    "\n",
    "\n",
    "class HCImporter(Importer):\n",
    "    def __init__(self, dataFolder: str = HCDataFolder, outputFolder: str = OutputFolder, outputFileName: str = HCOutputFileName):\n",
    "        super().__init__(dataFolder, outputFolder, outputFileName)\n",
    "\n",
    "    def _cleanFile(self, lang: Languages, file: str):\n",
    "        rawData = pd.read_csv(file)\n",
    "        rawData.rename(columns = {CFIADataCols.OldOtherTyping.value: CFIADataCols.NewOtherTyping.value}, inplace = True)\n",
    "\n",
    "        isEcoli = self.isEColi(rawData)\n",
    "        notTypedStr = Translations[lang][CFIADataCols.EColiTyped.value][\"Not Typed\"]\n",
    "\n",
    "        rawData[CFIADataCols.EColiTyped.value] = np.where(isEcoli, notTypedStr, \"\")\n",
    "        rawData[CFIADataCols.IsVirulent.value] = \"\"\n",
    "\n",
    "        outputFile = os.path.join(self.outputFolder, f\"{self.outputFileName}-{lang.value}.csv\")\n",
    "        print(f\"Writing HC CSV output for language: {lang.value} ...\\n\", end = \"\")\n",
    "        rawData.to_csv(outputFile, index = False, encoding = \"utf-8\")\n",
    "\n",
    "    def run(self):\n",
    "        threads = ThreadManager()\n",
    "        for lang in Languages:\n",
    "            inputFile = os.path.join(self.dataFolder, f\"CANLINE Micro w quant data - no protB values- export 2022-09-14-{lang.value}.csv\")\n",
    "            threads.add(target = self._cleanFile, args = [lang, inputFile])\n",
    "\n",
    "        threads.waitAll()\n",
    "\n",
    "\n",
    "########\n",
    "# MAIN #\n",
    "########\n",
    "cfiaImporter = CFIAImporter()\n",
    "hcImporter = HCImporter()\n",
    "\n",
    "threads = ThreadManager()\n",
    "threads.add(target = cfiaImporter.run)\n",
    "threads.add(target = hcImporter.run)\n",
    "threads.waitAll()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
