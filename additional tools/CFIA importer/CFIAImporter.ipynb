{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFIA Importer\n",
    "[![Static Badge](https://img.shields.io/badge/Jupyter_Notebook-F37726?style=for-the-badge)](https://jupyter.org/)\n",
    "\n",
    "<br>\n",
    "\n",
    "## Requirements\n",
    "- Python (Version 3.6 or up)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Install Required Dependencies\n",
    "Run the code block below to install the required dependencies.\n",
    "\n",
    "<br>\n",
    "\n",
    "> ***üìù NOTE:*** <br>\n",
    ">\n",
    "> If you already have the required dependencies, you can *optionally* run the code block below.\n",
    "> \n",
    "> (For this case, running the code will only import the required libraries without sending any HTTP server requests to Pypi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Note: The code below is modified from AGRemap for dynamically installing\n",
    "#   packages at runtime. That way, we do not need to make extra HTTP requests\n",
    "#   to Pypi's server if the user's python environment already has the required libraries\n",
    "#\n",
    "# Reference:\n",
    "#    https://github.com/nhok0169/Anime-Game-Remap/blob/nhok0169/Anime%20Game%20Remap%20(for%20all%20users)/api/src/FixRaidenBoss2/tools/PackageManager.py\n",
    "#    https://github.com/nhok0169/Anime-Game-Remap/blob/nhok0169/Anime%20Game%20Remap%20(for%20all%20users)/api/src/FixRaidenBoss2/tools/PackageData.py\n",
    "\n",
    "\n",
    "import pip._internal as pip\n",
    "import importlib\n",
    "from types import ModuleType\n",
    "from typing import Optional, Dict\n",
    "\n",
    "\n",
    "# PackageData: Class to hold data for importing a package\n",
    "class PackageData():\n",
    "    def __init__(self, module: str, installName: Optional[str] = None):\n",
    "        self.module = module\n",
    "        self.installName = module if (installName is None) else installName\n",
    "\n",
    "\n",
    "# PackageManager: Class to manage the packages\n",
    "class PackageManager():\n",
    "    def __init__(self):\n",
    "        self._packages: Dict[str, ModuleType] = {}\n",
    "\n",
    "    # load(module, installName, save): Tries to import a package and install the package if the package\n",
    "    #   is not installed yet. Can optionally save to cache.\n",
    "    def load(self, module: str, installName: Optional[str] = None, save: bool = True) -> ModuleType:\n",
    "        if (installName is None):\n",
    "            installName = module\n",
    "\n",
    "        try:\n",
    "            return importlib.import_module(module)\n",
    "        except ModuleNotFoundError:\n",
    "            pip.main(['install', '-U', installName])\n",
    "\n",
    "        result = importlib.import_module(module)\n",
    "        if (save):\n",
    "            self._packages[module] = result\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # get(packageData, cache): Retrieves a package and installs the package if the package is not installed yet.\n",
    "    #   Has optional caching capability.\n",
    "    def get(self, packageData: PackageData, cache: bool = True) -> ModuleType:\n",
    "        if (not cache):\n",
    "            return self.load(packageData.module, installName = packageData.installName, save = cache)\n",
    "\n",
    "        result = None\n",
    "        try:\n",
    "            result = self._packages[packageData.module]\n",
    "        except KeyError:\n",
    "            result = self.load(packageData.module, installName = packageData.installName, save = cache)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "##############################\n",
    "# The required installations #\n",
    "# ############################\n",
    "Packages = [\n",
    "    PackageData(\"pandas\"),\n",
    "    PackageData(\"openpyxl\")\n",
    "]\n",
    "\n",
    "Packager = PackageManager()\n",
    "\n",
    "for package in Packages:\n",
    "    Packager.get(package, cache = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## User Settings\n",
    "\n",
    "Below shows some configurations that may be different depending on the user.\n",
    "\n",
    "<br>\n",
    "\n",
    "> ***‚ùáÔ∏è Important***\n",
    ">\n",
    "> Please ensure settings below are configured correctly.\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The folder where the raw data files are located\n",
    "DataFolder = \"data\"\n",
    "\n",
    "# The file location to the output files \n",
    "OutputFolder = os.path.join(\"..\", \"..\", \"data\")\n",
    "OutputFileName = \"CFIA Data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Running the Importer\n",
    "\n",
    "The code blocks below cleans up the raw CFIA data files to look similar to the Health Canada data\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing CSV output for language: en ...\n",
      "Writing CSV output for language: fr ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from threading import Lock, Thread\n",
    "from enum import Enum\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# Languages: Different languages available\n",
    "class Languages(Enum):\n",
    "    English = \"en\"\n",
    "    French = \"fr\"\n",
    "\n",
    "\n",
    "# CFIADataCols: Different columns for the CFIA data\n",
    "class CFIADataCols(Enum):\n",
    "    FoodGroup = \"Food Group\"\n",
    "    FoodName = \"Food Name\"\n",
    "    Agent = \"Agent\"\n",
    "    Genus = \"Genus\"\n",
    "    Species = \"Species\"\n",
    "    SeroType = \"Serotype\"\n",
    "    EColiCategory = \"Ecoli CFIA Category\"\n",
    "\n",
    "\n",
    "# CFIAStrConsts: Some string keywords used in the raw CFIA data\n",
    "class CFIAStrConsts(Enum):\n",
    "    LangSeperator = \"//\"\n",
    "\n",
    "\n",
    "# index position for each language part in to retrieve from the raw CFIA data\n",
    "CFIALangPos = {Languages.English: 0, Languages.French: 1}\n",
    "\n",
    "# Columns to have english and french seperated\n",
    "CFIALangSeperatedCols = [CFIADataCols.FoodName.value]\n",
    "\n",
    "\n",
    "# Importer: Class to cleanup the CFIA data\n",
    "class Importer():\n",
    "    def __init__(self, dataFolder: str = DataFolder, outputFolder: str = OutputFolder, outputFileName: str = OutputFileName):\n",
    "        self.dataFolder = dataFolder\n",
    "        self.outputFolder = outputFolder\n",
    "        self.outputFileName = outputFileName\n",
    "\n",
    "        self._outputDataLocks = {}\n",
    "        self._outputData = {}\n",
    "\n",
    "        for lang in Languages:\n",
    "            self._outputDataLocks[lang] = Lock()\n",
    "            self._outputData[lang] = None\n",
    "\n",
    "    # _seperateTranslationCol(colValue): Seperate out a value consisting of the combined\n",
    "    #   translations into individual translated parts\n",
    "    @classmethod\n",
    "    def _seperateTranslationVal(cls, colValue: str) -> List[str]:\n",
    "        result = colValue.split(CFIAStrConsts.LangSeperator.value)\n",
    "        result = list(map(lambda translatedPart: translatedPart.strip(), result))\n",
    "\n",
    "        langLen = len(Languages)\n",
    "        resultLen = len(result)\n",
    "\n",
    "        if (resultLen == langLen):\n",
    "            return result\n",
    "        elif (resultLen > langLen):\n",
    "            return result[:langLen]\n",
    "        \n",
    "        for i in range(resultLen, langLen):\n",
    "            result.append(result[0])\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # _seperateTranslationCol(col, rawData, data, dataLocks): Seperate out the combined translated values in a column\n",
    "    def _seperateTranslationCol(self, col: str, rawData: pd.DataFrame, data: Dict[Languages, pd.DataFrame], dataLocks: Dict[Languages, Lock]):\n",
    "        colVals = rawData.get(col)\n",
    "        colVals = colVals.apply(self._seperateTranslationVal)\n",
    "\n",
    "        for lang in Languages:\n",
    "            currentData = data[lang]\n",
    "            langInd = CFIALangPos[lang]\n",
    "            lock = dataLocks[lang]\n",
    "\n",
    "            with lock:\n",
    "                currentData[col] = colVals.apply(lambda langFoodGroups: langFoodGroups[langInd])\n",
    "\n",
    "    # _seperateTranslations(rawData, data, rawDataLock, dataLocks): Seperate out the combined translated values from the raw data\n",
    "    #   for each seperate language result data\n",
    "    def _seperateTranslations(self, rawData: pd.DataFrame, data: Dict[Languages, pd.DataFrame], dataLocks: Dict[Languages, Lock]):\n",
    "        colThreads = []\n",
    "        for col in CFIALangSeperatedCols:\n",
    "            colThreads.append(Thread(target = self._seperateTranslationCol, args = [col, rawData, data, dataLocks], daemon=True))\n",
    "\n",
    "        for thread in colThreads:\n",
    "            thread.start()\n",
    "\n",
    "        for thread in colThreads:\n",
    "            thread.join()\n",
    "\n",
    "    # _createEColiCategory(rawData, data, dataLocks): Creates the E-Coli category for the microorganism breadcrumb\n",
    "    def _createEColiCategory(self, rawData: pd.DataFrame, data: Dict[Languages, pd.DataFrame], dataLocks: Dict[Languages, Lock]):\n",
    "        rowCount = len(rawData.index)\n",
    "        eColiCategoryVals = np.zeros(rowCount)\n",
    "\n",
    "        agentVals = rawData[CFIADataCols.Agent.value]\n",
    "        genusVals = rawData[CFIADataCols.Genus.value]\n",
    "        speciesVals = rawData[CFIADataCols.Species.value]\n",
    "        seroTypeVals = rawData[CFIADataCols.SeroType.value].fillna(\"\")\n",
    "\n",
    "        isEColi = ((agentVals == \"Bacteria\") & (genusVals == \"Escherichia\") & (speciesVals == \"coli\"))\n",
    "\n",
    "        seroTypeIsO157 = seroTypeVals.str.contains(pat = \"O157\")\n",
    "        seroTypeNotO157 = ~seroTypeIsO157\n",
    "\n",
    "        eColiCategoryVals = np.select([isEColi & seroTypeIsO157, isEColi & seroTypeNotO157], [\"O157\", \"Verotoxigenic\"], default = \"\")\n",
    "\n",
    "        for lang in Languages:\n",
    "            currentData = data[lang]\n",
    "            lock = dataLocks[lang]\n",
    "\n",
    "            with lock:\n",
    "                currentData[CFIADataCols.EColiCategory.value] = eColiCategoryVals\n",
    "\n",
    "    # processFile(excelFile): Cleanups a single excel file and merges the\n",
    "    #   result into the output data\n",
    "    def processFile(self, excelFile: str):\n",
    "        rawData = pd.read_excel(excelFile)\n",
    "\n",
    "        resultData = {}\n",
    "        resultDataLocks = {}\n",
    "        for lang in Languages:\n",
    "            resultData[lang] = rawData.copy()\n",
    "            resultDataLocks[lang] = Lock()\n",
    "\n",
    "        # Since the procedure for cleaning/creating the columns do not have any data\n",
    "        #   that depend on each other, we can run all these procedures in parallel\n",
    "        colThreads = []\n",
    "        colThreads.append(Thread(target = self._seperateTranslations, args = [rawData, resultData, resultDataLocks], daemon=True))\n",
    "        colThreads.append(Thread(target = self._createEColiCategory, args = [rawData, resultData, resultDataLocks], daemon=True))\n",
    "\n",
    "        for thread in colThreads:\n",
    "            thread.start()\n",
    "\n",
    "        for thread in colThreads:\n",
    "            thread.join()\n",
    "\n",
    "        # write the processed data back to the combined output\n",
    "        for lang in Languages:\n",
    "            lock = self._outputDataLocks[lang]\n",
    "\n",
    "            with lock:\n",
    "                outputData = self._outputData[lang]\n",
    "                self._outputData[lang] = resultData[lang].copy() if (outputData is None) else pd.concat([outputData, resultData[lang]])\n",
    "\n",
    "    # run(): Runs the importer to create the cleaned-up data\n",
    "    def run(self):\n",
    "        excelFiles = glob.glob(os.path.join(f\"{self.dataFolder}\", \"*.xlsx\"))\n",
    "\n",
    "        # simultaneously process multiple excel files at the same time\n",
    "        excelThreads = []\n",
    "        for excelFile in excelFiles:\n",
    "            csvThread = Thread(target = self.processFile, args=[excelFile], daemon=True)\n",
    "            excelThreads.append(csvThread)\n",
    "            csvThread.start()\n",
    "\n",
    "        # wait for all excel processes to finish\n",
    "        for thread in excelThreads:\n",
    "            thread.join()\n",
    "\n",
    "        for lang in Languages:\n",
    "            outputData = self._outputData[lang]\n",
    "            if (outputData is None):\n",
    "                continue\n",
    "            \n",
    "            file = os.path.join(self.outputFolder, f\"{self.outputFileName}-{lang.value}.csv\")\n",
    "            print(f\"Writing CSV output for language: {lang.value} ...\")\n",
    "            outputData.to_csv(file, index = False, encoding = \"utf-8\")\n",
    "\n",
    "\n",
    "########\n",
    "# MAIN #\n",
    "########\n",
    "importer = Importer()\n",
    "importer.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
